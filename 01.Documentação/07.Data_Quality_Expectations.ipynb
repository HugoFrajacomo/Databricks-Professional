{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2ad4686b-2df2-4d69-b0e1-848afce2e281",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Resumo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7f54ed26-708d-4f5d-bf5d-789324bdcd77",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "| Expectation | Conceito / Comportamento | Syntax SQL (DLT) | Syntax Python (DLT/PySpark) |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **Warn** | Permite que o registro inválido seja processado, mas gera um alerta nos logs de telemetria. | `CONSTRAINT nome EXPECT (condição)` | `@dlt.expect(\"nome\", \"condição\")` |\n",
    "| **Drop** | Remove o registro que falha na validação, impedindo que ele chegue ao destino. | `CONSTRAINT nome EXPECT (condição) ON VIOLATION DROP ROW` | `@dlt.expect_or_drop(\"nome\", \"condição\")` |\n",
    "| **Fail** | Interrompe imediatamente a execução do pipeline se qualquer registro violar a regra. | `CONSTRAINT nome EXPECT (condição) ON VIOLATION FAIL UPDATE` | `@dlt.expect_or_fail(\"nome\", \"condição\")` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f48fa01f-8fa1-44b8-bff0-dcc63548f97a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Exemplos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a5556062-e808-4bc3-b2c3-db51ca33cd07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REFRESH STREAMING TABLE my_table(\n",
    "  CONSTRAINT recent_status EXPECT (status = 'active' AND date >= '2025-01-01'),\n",
    "  CONSTRAINT positive_value EXPECT(value > 0) ON VIOLATION DROP ROW,\n",
    "  CONSTRAINT valid_id EXPECT(id IS NOT NULL) ON VIOLATION FAIL UPDATE\n",
    ") AS SELECT * FROM STREAM(source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b382aeb2-63b5-45a3-adff-0b04d21a1ecd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Python sintext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4ea75ba7-f993-4a72-88f5-5deaf47c2e14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dp.table\n",
    "@dp.table.expect(<constraint-name>, <condition>)\n",
    "@dp.expect_or_drop(<constraint-name>, <condition>)\n",
    "@dp.expect_or_fail(<constraint-name>, <condition>)\n",
    "def my_table():\n",
    "  return spark.sql(\"SELECT * FROM my_table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fca3e03f-0e8c-42b6-81dd-f511bc2732f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Exemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "56ef814d-a1f5-4b5d-96aa-df8935f2e9d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dp.table\n",
    "@dp.table.expect(\"recent_status\", \"status = 'Active' AND date >= '2022-01-01\")\n",
    "@dp.expect_or_drop(\"positive_value\", \"value > 0\")\n",
    "@dp.expect_or_fail(\"valid_id\", \"id IS NOT NULL\")\n",
    "def my_table():\n",
    "  return spark.readStream.table(\"my_table\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "07.Data_Quality_Expectations",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
