{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3a7ec04d-865f-4c88-b78d-3e339a0fd26d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Comparativo Técnico: Lakeflow Declarative Pipelines (LDP) vs. DLT e Spark\n",
    "\n",
    "| Característica | Lakeflow Declarative (LDP) | Delta Live Tables (DLT) / Spark Tradicional |\n",
    "| :--- | :--- | :--- |\n",
    "| **Importação de Módulo** | `from pyspark import pipelines as dp` | `import dlt` |\n",
    "| **Streaming Table (Python)** | `@dp.table` | `@dlt.table` |\n",
    "| **Materialized View (Python)**| `@dp.materialized_view` | `@dlt.table` (uso genérico) |\n",
    "| **Temporary View (Python)** | `@dp.temporary_view` | `@dlt.view` |\n",
    "| **Sintaxe SQL** | `CREATE OR REFRESH [OBJETO]` | Necessita PySpark para registrar tabelas de streaming |\n",
    "| **Orquestração** | Automática (checkpoints, retentativas e otimização) | Manual (exige `checkpointLocation` e `writeStream`) |\n",
    "| **Validação de Código** | Arquivos nativos (.py ou .sql) | Baseada em Notebooks |\n",
    "\n",
    "---\n",
    "\n",
    "### Definição dos Objetos no Ecossistema LDP\n",
    "\n",
    "| Objeto | Permanência | Função Principal | Método de Ingestão |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **Streaming Table** | Permanente | Ingestão incremental (append-only) e real-time | `spark.readStream` ou `STREAM()` |\n",
    "| **Materialized View**| Permanente | Pré-computação de BI e fontes não-streamable | `spark.read` |\n",
    "| **Temporary View** | Temporário | Transformações intermediárias e qualidade de dados | Fluxo interno |\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Comparativo de Objetos: Lakeflow Declarative Pipelines (LDP)\n",
    "\n",
    "| Característica | Streaming Tables | Materialized Views | Temporary Views |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **Permanência** | Objetos permanentes | Objetos permanentes | Objetos temporários |\n",
    "| **Tipo de Refresh** | Incremental | Total ou Incremental (Serverless) | Temporário |\n",
    "| **Uso Principal** | Ingestão de fontes streaming | Consultas complexas de BI | Transformações e Qualidade |\n",
    "| **Latência** | Baixa (Near real-time) | Média/Alta | N/A |\n",
    "| **Comando Python** | `spark.readStream` | `spark.read` | Lógica interna |\n",
    "| **Função SQL** | `STREAM()` | SQL Padrão | SQL Padrão |\n",
    "\n",
    "---\n",
    "\n",
    "**IMPORTANTE**: Para validar a exeção de uma dlt, deve estar atribuida a uma pipeline. Já a LDP é possivel executar um \"Dry run\" que não atualiza nenhuma data no teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "97087e0c-c280-44bf-8b24-90dbae79da78",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "06. LDP_vs_DLT",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
